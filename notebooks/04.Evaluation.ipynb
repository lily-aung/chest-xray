{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d3bdc6",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION\n",
    "\n",
    "At this stage, we evaluated several machine learning approaches across the following experimental setups:\n",
    "1.\tEnd-to-end deep learning using CNN-based models.\n",
    "2.\tLinear probing with frozen backbones, including ResNet, DenseNet, EfficientNet, and Swin-Tiny, followed by a linear classifier.\n",
    "3.\tHandcrafted feature pipelines, where HOG features were combined with downstream classifiers such as Multilayer Perceptrons, XGBoost (boosting), and Random Forests (bagging).\n",
    "\n",
    "We systematically selected the best-performing models from each training paradigm and evaluated them on a shared held-out test set, while preserving each model’s native preprocessing pipeline. The final deliverables are deployment-ready artifacts, including predictions, performance metrics, calibration analyses, and misclassification diagnostics.\n",
    "\n",
    "Model selection was driven entirely by MLflow experiment tracking, with no manual configuration files or subjective intervention in choosing the winning models. We ranked them by validation accuracy for CNN and best macro-model from the rest of the models.\n",
    "\n",
    "After identifying the top-performing models, we conducted detailed analyses of each winner, including threshold optimization to determine appropriate operating points aligned with clinical risk tolerance.\n",
    "\n",
    "We report comprehensive evaluation metrics, including AUC-ROC, F1 score, precision, recall, specificity, sensitivity, reliability diagrams for calibration metrics, and confusion matrices. Per-class metrics, along with macro- and micro-averaged results, are also provided.\n",
    "\n",
    "The thresholding strategy applies a conservative clinical risk tolerance that prioritizes minimizing false negatives for Tuberculosis and Pneumonia. This intentionally accepts higher false-positive rates and reduced recall for the Normal class as a trade-off to reduce the risk of missing severe disease cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e24343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/lily/Documents/Projects/chest-xray\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path.cwd().parent   \n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55341f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking URI: sqlite:////Users/lily/Documents/Projects/chest-xray/mlflow.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/14 14:12:24 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/14 14:12:24 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/01/14 14:12:24 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/14 14:12:24 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/14 14:12:24 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/14 14:12:24 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments: ['backbone-linear-probe', 'cnn-ablation-analysis', 'Default']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import mlflow\n",
    "\n",
    "PROJECT_ROOT = Path(\"/Users/lily/Documents/Projects/chest-xray\")\n",
    "mlflow.set_tracking_uri( f\"sqlite:///{PROJECT_ROOT}/mlflow.db\")\n",
    "\n",
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\"Experiments:\", [e.name for e in mlflow.search_experiments()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44daecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import argparse\n",
    "from src.train_hog import build_split\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.config import load_config, get_config_for_backbone\n",
    "from src.utils.mlflow_utils import get_best_run_from_experiment, get_best_linear_probe_runs, load_hog_summary, load_run_model_pytorch\n",
    "from src.data.dataset import build_test_dataset\n",
    "from src.data.dataloaders import build_dataloader\n",
    "from src.utils.eval_plots import *\n",
    "from src.utils.thresholds import *\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_torch(model, loader, device):\n",
    "    model.eval().to(device)\n",
    "    y_true, y_pred, probs_max, probs_all, paths = [], [], [], [], []\n",
    "    for batch in loader:\n",
    "        if len(batch) == 2:\n",
    "            images, labels = batch\n",
    "            batch_paths = [\"\"] * len(labels)\n",
    "        else:\n",
    "            images, labels, batch_paths = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(images)\n",
    "        if isinstance(logits, (tuple, list)):\n",
    "            logits = logits[0]\n",
    "        p = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(p, dim=1)\n",
    "        y_true.extend(labels.detach().cpu().numpy().tolist())\n",
    "        y_pred.extend(pred.detach().cpu().numpy().tolist())\n",
    "        probs_max.extend(p.max(dim=1).values.detach().cpu().numpy().tolist())\n",
    "        probs_all.append(p.detach().cpu().numpy())\n",
    "        paths.extend(list(batch_paths))\n",
    "    probs_all = np.concatenate(probs_all, axis=0) if probs_all else np.zeros((0, 0))\n",
    "    return np.array(y_true), np.array(y_pred), np.array(probs_max), probs_all, paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4769a145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Best CNN ===\n",
      " model                                        cnn\n",
      "run_name                       cnn-30-flip-clahe\n",
      "val_accuracy                            0.774665\n",
      "run_id          0578cf379372432998cb6eb00b25979a\n",
      "\n",
      "=== Best Linear Probes (per backbone) ===\n",
      "       backbone             run_name  val_macro_f1                           run_id\n",
      "   densenet121    densenet121-lp-20      0.775108 147c2b5d56654fb6ba05e53a7a2b927f\n",
      "     swin-tiny      swin-tiny-lp-20      0.770872 f507cd77d25042069bfff987a15a0a9a\n",
      "      resnet50       resnet50-lp-20      0.766328 4b3f6fc37ee34736a58f9375bce0f564\n",
      "efficientnetb0 efficientnetb0-lp-20      0.762740 7eee36d163784091ad402806b43df857\n",
      "\n",
      "=== HOG Baselines ===\n",
      " model  val_acc  val_macro_f1  test_acc  test_macro_f1  hog_dim  seed  clahe_clip clahe_grid  hog_ppc  hog_cpb  hog_orientations\n",
      "  mlp 0.740726      0.753487  0.744648       0.758272     6084     0         2.0     (8, 8)       16        2                 9\n",
      "  xgb 0.567482      0.582189  0.566368       0.584644     6084     0         2.0     (8, 8)       16        2                 9\n",
      "   rf 0.561563      0.575964  0.555080       0.572061     6084     0         2.0     (8, 8)       16        2                 9\n"
     ]
    }
   ],
   "source": [
    "out_root = Path(\"reports/best_model_eval\")\n",
    "out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#select best    \n",
    "best_cnn = get_best_run_from_experiment(experiment_name=\"cnn-ablation-analysis\", metric=\"val_accuracy\", maximize=True)\n",
    "best_lps = get_best_linear_probe_runs(experiment_name=\"backbone-linear-probe\", metric=\"val_macro_f1\", maximize=True)\n",
    "hog = load_hog_summary(str(PROJECT_ROOT / \"artifacts\" / \"hog_baselines\" / \"summary.csv\"), metric=\"val_macro_f1\")\n",
    "print(\"\\n=== Best CNN ===\\n\", best_cnn.to_string())\n",
    "print(\"\\n=== Best Linear Probes (per backbone) ===\\n\", best_lps.to_string(index=False))\n",
    "print(\"\\n=== HOG Baselines ===\\n\", hog.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80bcca3",
   "metadata": {},
   "source": [
    "We have selected a winner from each paradigm. DenseNet121 was chosen as the best LP model, and HOG with MLP was selected as the best non-deep-learning approach\n",
    "\n",
    "To reflect clinical deployment constraints, we evaluated models using a policy-aware decision framework instead of naive argmax classification. Class-specific thresholds were selected using one-vs-rest sweeps to satisfy minimum sensitivity requirements for Tuberculosis (≥90%) and Pneumonia (≥85%). \n",
    "\n",
    "Priority order: Tuberculosis → Pneumonia → Normal\n",
    "Clinical constraints: Tuberculosis: ≥ 90% sensitivity , Pneumonia: ≥ 85% sensitivity\n",
    "\n",
    "Final predictions were generated via a hierarchical decision rule (Tuberculosis → Pneumonia → Normal), prioritizing detection of high-risk conditions over overall accuracy.\n",
    "\n",
    "\n",
    "Model performance under this policy-aware framework was compared against the standard argmax baseline, with a particular focus on improvements in Tuberculosis sensitivity.\n",
    "\n",
    "This evaluation strategy mirrors realistic clinical deployment, where missing severe disease carries substantially higher cost than over-triage. Threshold selection was therefore guided by the objective of maximizing specificity subject to minimum sensitivity constraints, rather than overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f6d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN winner info\n",
    "cnn_run_id = best_cnn[\"run_id\"]\n",
    "cnn_run_name = best_cnn[\"run_name\"]\n",
    "\n",
    "#    # choose ONE LP winner overall (highest val_macro_f1)\n",
    "lp_winner = best_lps.sort_values(\"val_macro_f1\", ascending=False).iloc[0]\n",
    "lp_backbone = lp_winner[\"backbone\"]\n",
    "lp_run_id = lp_winner[\"run_id\"]\n",
    "lp_run_name = lp_winner[\"run_name\"]\n",
    "\n",
    "# - 2) Load configs (per-model) -\n",
    "cnn_cfg_path =  PROJECT_ROOT / \"configs\" / \"cnn.yaml\"\n",
    "lp_cfg_path = get_config_for_backbone(lp_backbone, config_dir=PROJECT_ROOT / \"configs\")\n",
    "cnn_cfg = load_config(cnn_cfg_path)\n",
    "lp_cfg = load_config(lp_cfg_path)\n",
    "cnn_class_names = getattr(cnn_cfg.data, \"class_names\", None) or getattr(cnn_cfg, \"class_names\", None) or []\n",
    "lp_class_names = getattr(lp_cfg.data, \"class_names\", None) or getattr(lp_cfg, \"class_names\", None) or []\n",
    "test_csv = PROJECT_ROOT / 'data' / 'test.csv'\n",
    "cnn_cfg.data.test_csv = test_csv\n",
    "lp_cfg.data.test_csv = test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba88a9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN test dataset len: 2569\n",
      "LP test dataset len: 2569\n"
     ]
    }
   ],
   "source": [
    "# - 3) Build test loaders (each model uses its own dataset/transforms) -\n",
    "cnn_test_ds = build_test_dataset(cnn_cfg, test_csv)\n",
    "cnn_test_loader = build_dataloader(cnn_test_ds, batch_size=cnn_cfg.training.batch_size,\n",
    "                                    shuffle=False, num_workers=cnn_cfg.data.num_workers)\n",
    "lp_test_ds = build_test_dataset(lp_cfg, test_csv)\n",
    "lp_test_loader = build_dataloader(lp_test_ds, batch_size=lp_cfg.training.batch_size, \n",
    "                                    shuffle=False, num_workers=lp_cfg.data.num_workers)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CNN test dataset len:\", len(cnn_test_ds))\n",
    "print(\"LP test dataset len:\", len(lp_test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22893916",
   "metadata": {},
   "source": [
    "##### - Load models from MLflow and predict -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ae6c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0578cf379372432998cb6eb00b25979a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798d5b2728874668aee40ed992112fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8a9ce020494ca7a92c850f81ff3e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x17fa99570>\n",
      " class_id   class_name  threshold  precision  recall_sensitivity  specificity       f1\n",
      "        1    Pneumonia       0.51   0.880071            0.860345     0.965812 0.870096\n",
      "        2 Tuberculosis       0.18   0.743034            0.902256     0.779402 0.814941\n",
      "Chosen thresholds: {'Pneumonia': 0.51, 'Tuberculosis': 0.18}\n"
     ]
    }
   ],
   "source": [
    "print(cnn_run_id)\n",
    "#cnn_model = load_run_model_pytorch(cnn_run_id, artifact_path=\"data\")\n",
    "cnn_model = load_run_model_pytorch(cnn_run_id)\n",
    "print(cnn_test_loader)\n",
    "y_true, y_pred, y_conf, probs_all, paths = predict_torch(cnn_model, cnn_test_loader, device)\n",
    "cnn_out = out_root / f\"cnn__{cnn_run_name}\"\n",
    "cnn_out.mkdir(parents=True, exist_ok=True)\n",
    "pd.DataFrame({\"path\": paths, \"y_true\": y_true, \"y_pred\": y_pred, \"confidence\": y_conf}).to_csv(cnn_out / \"predictions.csv\", index=False)\n",
    "cnn_report = compute_classification_report(y_true, y_pred, probs_all, cnn_class_names)\n",
    "#summary_df, per_class_df = report_tables(cnn_report)\n",
    "#summary_df.to_csv(cnn_out / \"summary_metrics.csv\", index=False)\n",
    "#per_class_df.to_csv(cnn_out / \"per_class_metrics.csv\", index=False)\n",
    "(cnn_out / \"report.json\").write_text(json.dumps(cnn_report, indent=2))\n",
    "names = cnn_class_names or [str(i) for i in range(probs_all.shape[1])]\n",
    "\n",
    "plot_confusion_and_classification_report(\n",
    "    y_true, y_pred, names, cnn_out / \"ConfusionMatrix_Classification.png\", title=\"CNN Classification Report\" )\n",
    "plot_misclassifications_bar(y_true, y_pred, names, cnn_out / \"misclass_by_true_class.png\")\n",
    "plot_roc_ovr_multiclass(probs_all, y_true, names, cnn_out / \"roc_ovr.png\")##x:FPR, y:TPR (Recall/sensiviity) ; AUC: higher better sep\n",
    "plot_pr_ovr_multiclass(probs_all, y_true, names, cnn_out / \"pr_ovr.png\")# X:Recall, Y:Precision\n",
    "plot_reliability_diagram_multiclass(probs_all, y_true, cnn_out / \"reliability.png\")\n",
    "\n",
    "thr = None\n",
    "if probs_all.shape[1] == 2:\n",
    "    sweep = threshold_sweep_binary(y_true, probs_all[:, 1])\n",
    "    sweep.to_csv(cnn_out / \"threshold_sweep.csv\", index=False)\n",
    "    op = pick_operating_point(sweep, min_sensitivity=0.90, objective=\"max_specificity\")\n",
    "    pd.DataFrame([op.to_dict()]).to_csv(cnn_out / \"operating_point.csv\", index=False)\n",
    "else:\n",
    "    sweep = threshold_sweep_ovr(y_true, probs_all, names)  #Onevsrest\n",
    "    sweep.to_csv(cnn_out / \"threshold_sweep_ovr.csv\", index=False)\n",
    "    ops = pick_operating_points_ovr( sweep, classes=[\"Tuberculosis\", \"Pneumonia\"],objective=\"max_specificity\",\n",
    "        min_sensitivity={\"Tuberculosis\": 0.90, \"Pneumonia\": 0.85}, min_precision={\"Tuberculosis\": 0.70})\n",
    "    print(ops.to_string(index=False))\n",
    "    ops.to_csv(cnn_out / \"operating_points_ovr.csv\", index=False) \n",
    "    thr = {r[\"class_name\"]: float(r[\"threshold\"]) for _, r in ops.iterrows()}\n",
    "    print(\"Chosen thresholds:\", thr)\n",
    "\n",
    "    # apply policy\n",
    "    y_pred_policy = predict_with_policy( probs_all, names, thr,priority=(\"Tuberculosis\", \"Pneumonia\"), fallback=\"Normal\")\n",
    "\n",
    "    plot_confusion_and_classification_report(  y_true, y_pred_policy, names, cnn_out / \"ConfusionMatrix_Classification_Policy.png\",\n",
    "        title=\"CNN Classification Report (Policy)\")\n",
    "\n",
    "    policy_report = compute_classification_report(y_true, y_pred_policy, probs_all, names)\n",
    "    summary_pol, per_class_pol = report_tables(policy_report)\n",
    "    summary_pol.to_csv(cnn_out / \"summary_metrics_policy.csv\", index=False)\n",
    "    per_class_pol.to_csv(cnn_out / \"per_class_metrics_policy.csv\", index=False)\n",
    "    (cnn_out / \"report_policy.json\").write_text(json.dumps(policy_report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abadb985",
   "metadata": {},
   "source": [
    "For TB; high sensitivity with acceptable specificity\n",
    "For Pne: its balanced \n",
    "For Normal : 0.98 and sensiviity is 0.006 => can't use threshold at all \n",
    "\n",
    "As TB high risk and Pneumonia next and noral is safe\n",
    "`test` \n",
    "If p(TB) > 0.18 => TB else p(Pneumonia) >=0.51 => Pneumonia; else: Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8d0730cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdaeed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147c2b5d56654fb6ba05e53a7a2b927f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c4057fe1d54c8e8a25b1086208fd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a59a5e5499c4a818bea1d95b95cfede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x176d404f0>\n",
      " class_id   class_name  threshold  precision  recall_sensitivity  specificity       f1\n",
      "        1    Pneumonia       0.47   0.851468            0.850000     0.956762 0.850733\n",
      "        2 Tuberculosis       0.05   0.705925            0.906955     0.732890 0.793912\n",
      "Chosen thresholds (LP): {'Pneumonia': 0.47000000000000003, 'Tuberculosis': 0.05}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Linear Probe: Load + Predict + Evaluate\n",
    "# =========================\n",
    "print(lp_run_id)\n",
    "lp_model = load_run_model_pytorch(lp_run_id)\n",
    "print(lp_test_loader)\n",
    "y_true_lp, y_pred_lp, y_conf_lp, probs_all_lp, paths_lp = predict_torch(lp_model, lp_test_loader, device)\n",
    "lp_out = out_root / f\"linearprobe__{lp_run_name}__{lp_backbone}\"\n",
    "lp_out.mkdir(parents=True, exist_ok=True)\n",
    "lp_names = lp_class_names or [str(i) for i in range(probs_all_lp.shape[1])]\n",
    "assert len(lp_names) == probs_all_lp.shape[1], f\"class_names mismatch: {lp_names} vs probs {probs_all_lp.shape}\"\n",
    "\n",
    "pred_df_lp = pd.DataFrame({ \"path\": paths_lp, \"y_true\": y_true_lp, \"y_pred\": y_pred_lp, \"confidence\": y_conf_lp})\n",
    "probs_df_lp = pd.DataFrame(probs_all_lp, columns=[f\"p_{n}\" for n in lp_names])\n",
    "pd.concat([pred_df_lp, probs_df_lp], axis=1).to_csv(lp_out / \"predictions.csv\", index=False)\n",
    "\n",
    "lp_report = compute_classification_report(y_true_lp, y_pred_lp, probs_all_lp, lp_names)\n",
    "(lp_out / \"report.json\").write_text(json.dumps(lp_report, indent=2))\n",
    "\n",
    "plot_confusion_and_classification_report( y_true_lp, y_pred_lp, lp_names, lp_out / \"ConfusionMatrix_Classification.png\",\n",
    "    title=\"Linear Probe Classification Report\" )\n",
    "plot_misclassifications_bar(y_true_lp, y_pred_lp, lp_names, lp_out / \"misclass_by_true_class.png\")\n",
    "plot_roc_ovr_multiclass(probs_all_lp, y_true_lp, lp_names, lp_out / \"roc_ovr.png\")\n",
    "plot_pr_ovr_multiclass(probs_all_lp, y_true_lp, lp_names, lp_out / \"pr_ovr.png\")\n",
    "plot_reliability_diagram_multiclass(probs_all_lp, y_true_lp, lp_out / \"reliability.png\")\n",
    "\n",
    "thr_lp = None\n",
    "if probs_all_lp.shape[1] == 2:\n",
    "    # binary case\n",
    "    sweep_lp = threshold_sweep_binary(y_true_lp, probs_all_lp[:, 1])\n",
    "    sweep_lp.to_csv(lp_out / \"threshold_sweep.csv\", index=False)\n",
    "    op_lp = pick_operating_point(sweep_lp, min_sensitivity=0.90, objective=\"max_specificity\")\n",
    "    pd.DataFrame([op_lp.to_dict()]).to_csv(lp_out / \"operating_point.csv\", index=False)\n",
    "\n",
    "else:   # multiclass OvR sweep\n",
    "    sweep_lp = threshold_sweep_ovr(y_true_lp, probs_all_lp, lp_names)\n",
    "    sweep_lp.to_csv(lp_out / \"threshold_sweep_ovr.csv\", index=False)\n",
    "\n",
    "    # Select operating points for priority classes only (Normal is fallback)\n",
    "    ops_lp = pick_operating_points_ovr( sweep_lp, classes=[\"Tuberculosis\", \"Pneumonia\"],objective=\"max_specificity\",\n",
    "        min_sensitivity={\"Tuberculosis\": 0.90, \"Pneumonia\": 0.85},\n",
    "        min_precision={\"Tuberculosis\": 0.70})\n",
    "    print(ops_lp.to_string(index=False))\n",
    "    ops_lp.to_csv(lp_out / \"operating_points_ovr.csv\", index=False)\n",
    "    thr_lp = {r[\"class_name\"]: float(r[\"threshold\"]) for _, r in ops_lp.iterrows()}\n",
    "    print(\"Chosen thresholds (LP):\", thr_lp)\n",
    "    # Apply policy (TB -> Pneumonia -> Normal)\n",
    "    y_pred_policy_lp = predict_with_policy( probs_all_lp, lp_names, thr_lp,\n",
    "        priority=(\"Tuberculosis\", \"Pneumonia\"), fallback=\"Normal\")\n",
    "\n",
    "    # Plot policy CM/report\n",
    "    plot_confusion_and_classification_report( y_true_lp, y_pred_policy_lp, lp_names,\n",
    "        lp_out / \"ConfusionMatrix_Classification_Policy.png\",\n",
    "        title=\"Linear Probe Classification Report (Policy)\" )\n",
    "\n",
    "    policy_report_lp = compute_classification_report(y_true_lp, y_pred_policy_lp, probs_all_lp, lp_names)\n",
    "    summary_pol_lp, per_class_pol_lp = report_tables(policy_report_lp)\n",
    "    summary_pol_lp.to_csv(lp_out / \"summary_metrics_policy.csv\", index=False)\n",
    "    per_class_pol_lp.to_csv(lp_out / \"per_class_metrics_policy.csv\", index=False)\n",
    "    (lp_out / \"report_policy.json\").write_text(json.dumps(policy_report_lp, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1239d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Build Features for HOG  <class 'str'>\n",
      " class_id   class_name  threshold  precision  recall_sensitivity  specificity       f1\n",
      "        1    Pneumonia       0.61   0.835593                0.85     0.951232 0.842735\n",
      "        2 Tuberculosis       0.01   0.579837                1.00     0.487708 0.734046\n",
      "Chosen thresholds (HOG): {'Pneumonia': 0.61, 'Tuberculosis': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# HOG Best Model: Load + Predict + Evaluate + Policy\n",
    "# =========================\n",
    "\n",
    "hog_best = hog.sort_values(\"val_macro_f1\", ascending=False).iloc[0].to_dict()\n",
    "hog_dir = Path(PROJECT_ROOT / \"artifacts/hog_baselines\")\n",
    "hog_model_name = hog_best.get(\"model\", \"xgb\")  # \"xgb\" / \"rf\" / \"mlp\"\n",
    "hog_model_path = hog_dir / f\"{hog_model_name}_model.joblib\"\n",
    "if not hog_model_path.exists():\n",
    "    raise FileNotFoundError(f\"HOG model not found: {hog_model_path}\")\n",
    "hog_model = joblib.load(hog_model_path)\n",
    "# HOG params extracted from summary.csv \n",
    "img_size = int(hog_best.get(\"img_size\", 224))\n",
    "clahe_clip = float(hog_best.get(\"clahe_clip\", 2.0))\n",
    "\n",
    "grid_str = str(hog_best.get(\"clahe_grid\", \"(8, 8)\")).replace(\"(\", \"\").replace(\")\", \"\")\n",
    "grid = tuple(int(x.strip()) for x in grid_str.split(\",\"))\n",
    "\n",
    "hog_ppc = int(hog_best.get(\"hog_ppc\", 16))\n",
    "hog_cpb = int(hog_best.get(\"hog_cpb\", 2))\n",
    "hog_orientations = int(hog_best.get(\"hog_orientations\", 9))\n",
    "\n",
    "#  Build HOG features: test set \n",
    "Xte, yte, pte = build_split(csv_path=test_csv, img_root=None, img_col='image_path',\n",
    "                                label_col='label', img_size=img_size, clip=clahe_clip, grid=grid, orientations=hog_orientations,\n",
    "                                ppc=hog_ppc, cpb=hog_cpb, augment_train=False)\n",
    "y_true_hog = np.array(yte)\n",
    "y_pred_hog = hog_model.predict(Xte)\n",
    "proba_hog = hog_model.predict_proba(Xte) if hasattr(hog_model, \"predict_proba\") else None\n",
    "if proba_hog is None:\n",
    "    # fallback: one-hot of predictions (no real probabilities)\n",
    "    n_classes = int(max(y_true_hog.max(), y_pred_hog.max())) + 1\n",
    "    probs_all_hog = np.eye(n_classes)[y_pred_hog].astype(float)\n",
    "    conf_hog = probs_all_hog.max(axis=1)\n",
    "else:\n",
    "    probs_all_hog = np.array(proba_hog)\n",
    "    conf_hog = probs_all_hog.max(axis=1)\n",
    "\n",
    "hog_out = out_root / f\"hog__{hog_model_name}\"\n",
    "hog_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#  Class names \n",
    "hog_class_names = cnn_class_names if cnn_class_names else [f\"class_{i}\" for i in range(probs_all_hog.shape[1])]\n",
    "names_hog = hog_class_names or [str(i) for i in range(probs_all_hog.shape[1])]\n",
    "assert len(names_hog) == probs_all_hog.shape[1], f\"class_names mismatch: {names_hog} vs probs {probs_all_hog.shape}\"\n",
    "\n",
    "#  Save predictions.csv (with per-class probabilities) \n",
    "pred_df_hog = pd.DataFrame({ \"path\": pte, \"y_true\": y_true_hog,  \"y_pred\": y_pred_hog, \"confidence\": conf_hog })\n",
    "probs_df_hog = pd.DataFrame(probs_all_hog, columns=[f\"p_{n}\" for n in names_hog])\n",
    "pd.concat([pred_df_hog, probs_df_hog], axis=1).to_csv(hog_out / \"predictions.csv\", index=False)\n",
    "#  Base report ; threshodling using augmax\n",
    "hog_report = compute_classification_report(y_true_hog, y_pred_hog, probs_all_hog, names_hog)\n",
    "summary_df, per_class_df = report_tables(hog_report)\n",
    "summary_df.to_csv(hog_out / \"summary_metrics.csv\", index=False)\n",
    "per_class_df.to_csv(hog_out / \"per_class_metrics.csv\", index=False)\n",
    "(hog_out / \"report.json\").write_text(json.dumps(hog_report, indent=2))\n",
    "plot_confusion_and_classification_report( y_true_hog, y_pred_hog, names_hog,\n",
    "    hog_out / \"ConfusionMatrix_Classification.png\",\n",
    "    title=f\"HOG ({hog_model_name}) Classification Report\" )\n",
    "plot_misclassifications_bar(y_true_hog, y_pred_hog, names_hog, hog_out / \"misclass_by_true_class.png\")\n",
    "plot_roc_ovr_multiclass(probs_all_hog, y_true_hog, names_hog, hog_out / \"roc_ovr.png\")\n",
    "plot_pr_ovr_multiclass(probs_all_hog, y_true_hog, names_hog, hog_out / \"pr_ovr.png\")\n",
    "plot_reliability_diagram_multiclass(probs_all_hog, y_true_hog, hog_out / \"reliability.png\")\n",
    "\n",
    "thr_hog = None\n",
    "if probs_all_hog.shape[1] == 2:#binary\n",
    "    sweep_hog = threshold_sweep_binary(y_true_hog, probs_all_hog[:, 1])\n",
    "    sweep_hog.to_csv(hog_out / \"threshold_sweep.csv\", index=False)\n",
    "    op_hog = pick_operating_point(sweep_hog, min_sensitivity=0.90, objective=\"max_specificity\")\n",
    "    pd.DataFrame([op_hog.to_dict()]).to_csv(hog_out / \"operating_point.csv\", index=False)\n",
    "\n",
    "else: #multiclass \n",
    "    sweep_hog = threshold_sweep_ovr(y_true_hog, probs_all_hog, names_hog)\n",
    "    sweep_hog.to_csv(hog_out / \"threshold_sweep_ovr.csv\", index=False)\n",
    "    ops_hog = pick_operating_points_ovr(\n",
    "        sweep_hog,\n",
    "        classes=[\"Tuberculosis\", \"Pneumonia\"],     # exclude Normal (fallback)\n",
    "        objective=\"max_specificity\",\n",
    "        min_sensitivity={\"Tuberculosis\": 0.90, \"Pneumonia\": 0.85},\n",
    "        min_precision={\"Tuberculosis\": 0.70})      # prevents TB threshold too low\n",
    "    print(ops_hog.to_string(index=False))\n",
    "    ops_hog.to_csv(hog_out / \"operating_points_ovr.csv\", index=False)\n",
    "    thr_hog = {r[\"class_name\"]: float(r[\"threshold\"]) for _, r in ops_hog.iterrows()}\n",
    "    print(\"Chosen thresholds (HOG):\", thr_hog)\n",
    "\n",
    "    y_pred_policy_hog = predict_with_policy( probs_all_hog, names_hog, thr_hog, \n",
    "                                            priority=(\"Tuberculosis\", \"Pneumonia\"), fallback=\"Normal\")\n",
    "\n",
    "    plot_confusion_and_classification_report( y_true_hog, y_pred_policy_hog, names_hog,\n",
    "        hog_out / \"ConfusionMatrix_Classification_Policy.png\",\n",
    "        title=f\"HOG ({hog_model_name}) Classification Report (Policy)\")\n",
    "\n",
    "    policy_report_hog = compute_classification_report(y_true_hog, y_pred_policy_hog, probs_all_hog, names_hog)\n",
    "    summary_pol_hog, per_class_pol_hog = report_tables(policy_report_hog)\n",
    "    summary_pol_hog.to_csv(hog_out / \"summary_metrics_policy.csv\", index=False)\n",
    "    per_class_pol_hog.to_csv(hog_out / \"per_class_metrics_policy.csv\", index=False)\n",
    "    (hog_out / \"report_policy.json\").write_text(json.dumps(policy_report_hog, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d5651",
   "metadata": {},
   "source": [
    "The decision policy adopts a conservative risk posture, prioritizing low false negatives for Tuberculosis and Pneumonia, even at the cost of higher false positives and reduced Normal recall to avoid missing serious disease.\n",
    "\n",
    "Among the models, the CNN offers the best balance of sensitivity, specificity, and calibration. It is the most deployment-ready option, delivering reliable probabilities that support thresholding while maintaining high disease sensitivity without excessive over-flagging of normal cases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chest-xray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
